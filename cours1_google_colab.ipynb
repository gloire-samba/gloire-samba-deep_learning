{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1-JgkJYwkyM"
      },
      "source": [
        "# Code Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EemZRH1Ds3QK"
      },
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Charger les données MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normaliser les images pour que les valeurs soient entre 0 et 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convertir les labels en one-hot encoding\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "# Construire le modèle de réseau de neurones\n",
        "model = Sequential([\n",
        "    # Aplatir les images 28x28 en un vecteur de 784 pixels\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    # Couche dense (entièrement connectée) avec 128 neurones et la fonction d'activation ReLU\n",
        "    Dense(128, activation='relu'),\n",
        "    # Couche de sortie avec 10 neurones (un pour chaque chiffre) et la fonction d'activation softmax\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiler le modèle avec l'optimiseur Adam et la fonction de perte categorical_crossentropy\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Évaluer le modèle avec les données de test\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Précision du modèle : {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFu6vkgMwpxl"
      },
      "source": [
        "# Code Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xOd9q27wtDM"
      },
      "outputs": [],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Préparer les données avec des transformations : convertir en tenseurs et normaliser\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Créer des DataLoader pour charger les données par batch\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Définir le modèle de réseau de neurones\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Entraîner le modèle\n",
        "for epoch in range(5):\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Évaluer le modèle\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Précision du modèle : {100 * correct / total:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
